{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 5175158,
          "sourceType": "datasetVersion",
          "datasetId": 3008205,
          "isSourceIdPinned": false
        }
      ],
      "dockerImageVersionId": 30839,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "PROYECTO_FINAL_GIGA_SCIENCE_EEGMI_GCPDS",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1004516/SE-ALES-Y-SISTEMAS/blob/main/Proyecto_Final_SyS/PROYECTO_FINAL_GIGA_SCIENCE_EEGMI_GCPDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "dggarciam94_giga_science_gcpds_path = kagglehub.dataset_download('dggarciam94/giga-science-gcpds')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ZlCrqn7CZq0h"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto Final Señales y Sistemas 2025 -2\n",
        "\n",
        "## Presentado por:\n",
        "- Eduardo Yesid Aza Patiño\n",
        "- Cristian David Chalaca Salas\n",
        "- Gabriel Alejandro Gomez Mueses\n",
        "## **Objetivo**: Implementar técnicas de representación en tiempo y frecuencia para el reconocimiento de señales de electroencefalografía (EEG) en tareas de imaginación motora (Motor Imagery)\n",
        "\n",
        "\n",
        "![eegMI](https://figures.semanticscholar.org/288a54f091264377eccc99a19079c9387d66a78f/3-Figure2-1.png)\n",
        "\n",
        "Las señales de EEG pueden ser ruidosas debido a diversas fuentes, incluidos artefactos fisiológicos e interferencias electromagnéticas. También pueden variar de persona a persona, lo que dificulta la extracción de características y la comprensión de las señales. Además, esta variabilidad, influenciada por factores genéticos y cognitivos, presenta desafíos para el desarrollo de soluciones independientes del sujeto.\n",
        "\n",
        "**Base de datos**: GiGaScience Database [https://gigadb.org/dataset/100295](https://gigadb.org/dataset/100295)\n",
        "\n",
        "Ver Sección 3.1 en [Multimodal Explainability Using Class Activation Maps and Canonical Correlation for MI-EEG Deep Learning Classification](https://www.mdpi.com/2076-3417/14/23/11208)"
      ],
      "metadata": {
        "id": "B-uwZaL7Zq0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalamos las librerias necesarias\n",
        "\n",
        "## Ejercicio 1\n",
        "Consultar para qué sirven las siguientes librerías"
      ],
      "metadata": {
        "id": "k6MCeEdQZq0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow==2.15.0\n",
        "!pip install mne==1.6.0\n",
        "!pip install braindecode===0.7\n",
        "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:29:41.682463Z",
          "iopub.execute_input": "2025-12-12T23:29:41.682846Z",
          "iopub.status.idle": "2025-12-12T23:30:09.262625Z",
          "shell.execute_reply.started": "2025-12-12T23:29:41.682808Z",
          "shell.execute_reply": "2025-12-12T23:30:09.26145Z"
        },
        "scrolled": true,
        "_kg_hide-input": false,
        "id": "ZwEzkwrXZq0p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**solucion**\n",
        "\n",
        "**TensorFlow:**\n",
        "\n",
        "TensorFlow es una de las bibliotecas más populares para aprendizaje profundo (deep learning). Sirve para:\n",
        "\n",
        "* Construir y entrenar redes neuronales artificiales.\n",
        "* Manejar grandes cantidades de datos para el aprendizaje automático.\n",
        "* Implementar modelos de visión por computadora, procesamiento de lenguaje natural, reconocimiento de voz, etc.\n",
        "  \n",
        "**mne:**\n",
        "  \n",
        "MNE (Magnetoencephalography & Electroencephalography) es una librería especializada en el análisis de señales cerebrales como:\n",
        "\n",
        "* EEG (Electroencefalografía): actividad eléctrica del cerebro.\n",
        "* MEG (Magnetoencefalografía): campos magnéticos producidos por la actividad cerebral.\n",
        "* ECG (Electrocardiografía): actividad eléctrica del corazón.\n",
        "\n",
        "**Braindecode:**\n",
        "Braindecode es una librería basada en PyTorch y MNE, especializada en aprendizaje profundo para el análisis de señales cerebrales. Se usa para:\n",
        "\n",
        "* Clasificación de EEG en tareas de BCI (Interfaz Cerebro-Computadora).\n",
        "* Extracción de características de señales cerebrales.\n",
        "* Aplicaciones médicas y neurocientíficas.\n",
        "\n",
        "**git+https://github.com/UN-GCPDS/python-gcpds.databases:**\n",
        "  \n",
        "Este paquete proviene del Grupo de Procesamiento de Señales de la Universidad de Navarra (GCPDS) y parece estar relacionado con bases de datos para señales biomédicas.\n",
        "\n",
        "Al instalarlo desde GitHub, indica que el paquete está en desarrollo y proporciona acceso a:\n",
        "\n",
        "* Bases de datos de EEG/MEG para experimentos en neurociencia.\n",
        "* Herramientas para manejar y procesar señales biomédicas.\n",
        "\n",
        "**Concluciones:**\n",
        "\n",
        "* tensorflow: Para redes neuronales y aprendizaje profundo.\n",
        "* mne: Para análisis de señales cerebrales EEG/MEG/ECG.\n",
        "* braindecode: Para deep learning en neurociencia.\n",
        "* gcpds.databases: Para acceder a bases de datos biomédicas.\n"
      ],
      "metadata": {
        "id": "F_OJ4-tWZq0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importamos algunas librerias necesarias"
      ],
      "metadata": {
        "id": "cdds_RCrZq0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import resample\n",
        "from scipy.signal import freqz, filtfilt, resample\n",
        "from scipy.signal import butter as bw\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow as tf\n",
        "from gcpds.databases import GIGA_MI_ME\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:09.264203Z",
          "iopub.execute_input": "2025-12-12T23:30:09.264504Z",
          "iopub.status.idle": "2025-12-12T23:30:12.843803Z",
          "shell.execute_reply.started": "2025-12-12T23:30:09.264479Z",
          "shell.execute_reply": "2025-12-12T23:30:12.842845Z"
        },
        "id": "4_-oHtIsZq0s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* resample: Cambia la frecuencia de muestreo de una señal.\n",
        "* freqz: Muestra la respuesta en frecuencia de un filtro digital.\n",
        "* filtfilt:Filtra una señal sin distorsión de fase (usa filtrado hacia adelante y hacia atrás).\n",
        "* butter as bw:Diseña un filtro de Butterworth (ideal para señales EEG).\n",
        "\n",
        "**Usos en EEG: Filtrado de señales, eliminación de ruido, re-muestreo de señales para análisis en distintas bandas de frecuencia.**\n",
        "  \n",
        "**pandas (Manejo de datos)**\n",
        "Pandas es una de las librerías más utilizadas en manipulación y análisis de datos.\n",
        "\n",
        "* Se usa para leer archivos CSV, estructurar datos en dataframes y realizar operaciones sobre ellos.\n",
        "* Usos en EEG: Almacenar señales, etiquetas de clase (izquierda/derecha en BCI), tiempos de eventos.\n",
        "\n",
        "**random (Generación de números aleatorios)**\n",
        "* Módulo para generar números aleatorios en Python.\n",
        "* Usos en EEG: Creación de conjuntos de entrenamiento/test, generación de ruido simulado.\n",
        "\n",
        "**numpy (Cálculo numérico y manipulación de matrices)**\n",
        "* NumPy es una librería optimizada para cálculos numéricos con matrices y vectores.\n",
        "* Usos en EEG: Almacenamiento de señales, cálculos matemáticos en procesamiento de datos.\n",
        "\n",
        " **matplotlib.pyplot (Visualización de datos)**\n",
        "* Matplotlib permite crear gráficos y visualizar datos.\n",
        "* Usos en EEG: Graficar señales EEG, visualizar espectros de frecuencia.\n",
        "\n",
        "**tensorflow (Desactivado en tu código)**\n",
        "TensorFlow se usa para aprendizaje profundo, pero está comentado en tu código. Se usa en clasificación de señales cerebrales con redes neuronales.\n",
        "\n",
        "*  Usos en EEG: Modelos de aprendizaje profundo para detección de patrones en señales.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dcpyQp80Zq0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones necesarias para el preprocesamiento leve de los datos"
      ],
      "metadata": {
        "id": "8d3-SMbWZq0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_GIGA(db,\n",
        "              sbj,\n",
        "              eeg_ch_names,\n",
        "              new_fs,\n",
        "              fs,\n",
        "              f_bank=None,\n",
        "              vwt=None,\n",
        "              run=None):\n",
        "\n",
        "    index_eeg_chs = db.format_channels_selectors(channels = eeg_ch_names) - 1\n",
        "\n",
        "    #tf_repr = TimeFrequencyRpr(sfreq = fs, f_bank = f_bank, vwt = vwt)\n",
        "\n",
        "    db.load_subject(sbj)\n",
        "    if run == None:\n",
        "        X, y = db.get_data(classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n",
        "    else:\n",
        "        X, y = db.get_run(run, classes = ['left hand mi', 'right hand mi']) #Load MI classes, all channels {EEG}, reject bad trials, uV\n",
        "    X = X[:, index_eeg_chs, :] #spatial rearrangement\n",
        "    #X = np.squeeze(tf_repr.transform(X))\n",
        "    #Resampling\n",
        "    if new_fs == fs:\n",
        "        pass#print('No resampling, since new sampling rate same.')\n",
        "    else:\n",
        "        print(\"Resampling from {:f} to {:f} Hz.\".format(fs, new_fs))\n",
        "        X = resample(X, int((X.shape[-1]/fs)*new_fs), axis = -1)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def butterworth_digital_filter(X, N, Wn, btype, fs, axis=-1, padtype=None, padlen=0, method='pad', irlen=None):\n",
        "  \"\"\"\n",
        "  Apply digital butterworth filter\n",
        "  INPUT\n",
        "  ------\n",
        "  1. X: (D array)\n",
        "    array with signals.\n",
        "  2. N: (int+)\n",
        "    The order of the filter.\n",
        "  3. Wn: (float+ or 1D array)\n",
        "    The critical frequency or frequencies. For lowpass and highpass filters, Wn is a scalar; for bandpass and bandstop filters, Wn is a length-2 vector.\n",
        "    For a Butterworth filter, this is the point at which the gain drops to 1/sqrt(2) that of the passband (the “-3 dB point”).\n",
        "    If fs is not specified, Wn units are normalized from 0 to 1, where 1 is the Nyquist frequency (Wn is thus in half cycles / sample and defined as 2*critical frequencies / fs). If fs is specified, Wn is in the same units as fs.\n",
        "  4. btype: (str) {‘lowpass’, ‘highpass’, ‘bandpass’, ‘bandstop’}\n",
        "    The type of filter\n",
        "  5. fs: (float+)\n",
        "    The sampling frequency of the digital system.\n",
        "  6. axis: (int), Default=1.\n",
        "    The axis of x to which the filter is applied.\n",
        "  7. padtype: (str) or None, {'odd', 'even', 'constant'}\n",
        "    This determines the type of extension to use for the padded signal to which the filter is applied. If padtype is None, no padding is used. The default is ‘odd’.\n",
        "  8. padlen: (int+) or None, Default=0\n",
        "    The number of elements by which to extend x at both ends of axis before applying the filter. This value must be less than x.shape[axis] - 1. padlen=0 implies no padding.\n",
        "  9. method: (str), {'pad', 'gust'}\n",
        "    Determines the method for handling the edges of the signal, either “pad” or “gust”. When method is “pad”, the signal is padded; the type of padding is determined by padtype\n",
        "    and padlen, and irlen is ignored. When method is “gust”, Gustafsson’s method is used, and padtype and padlen are ignored.\n",
        "  10. irlen: (int) or None, Default=nONE\n",
        "    When method is “gust”, irlen specifies the length of the impulse response of the filter. If irlen is None, no part of the impulse response is ignored.\n",
        "    For a long signal, specifying irlen can significantly improve the performance of the filter.\n",
        "  OUTPUT\n",
        "  ------\n",
        "  X_fil: (D array)\n",
        "    array with filtered signals.\n",
        "  \"\"\"\n",
        "  b, a = bw(N, Wn, btype, analog=False, output='ba', fs=fs)\n",
        "  return filtfilt(b, a, X, axis=axis, padtype=padtype, padlen=padlen, method=method, irlen=irlen)\n",
        "\n",
        "class TimeFrequencyRpr(BaseEstimator, TransformerMixin):\n",
        "  \"\"\"\n",
        "  Time frequency representation of EEG signals.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "    1. sfreq:  (float) Sampling frequency in Hz.\n",
        "    2. f_bank: (2D array) Filter banks Frequencies. Default=None\n",
        "    3. vwt:    (2D array) Interest time windows. Default=None\n",
        "  Methods\n",
        "  -------\n",
        "    1. fit(X, y=None)\n",
        "    2. transform(X, y=None)\n",
        "  \"\"\"\n",
        "  def __init__(self, sfreq, f_bank=None, vwt=None):\n",
        "    self.sfreq = sfreq\n",
        "    self.f_bank = f_bank\n",
        "    self.vwt = vwt\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "  def _validation_param(self):\n",
        "    \"\"\"\n",
        "    Validate Time-Frequency characterization parameters.\n",
        "    INPUT\n",
        "    -----\n",
        "      1. self\n",
        "    ------\n",
        "      2. None\n",
        "    \"\"\"\n",
        "    if self.sfreq <= 0:\n",
        "      raise ValueError('Non negative sampling frequency is accepted')\n",
        "\n",
        "\n",
        "    if self.f_bank is None:\n",
        "      self.flag_f_bank = False\n",
        "    elif self.f_bank.ndim != 2:\n",
        "      raise ValueError('Band frequencies have to be a 2D array')\n",
        "    else:\n",
        "      self.flag_f_bank = True\n",
        "\n",
        "    if self.vwt is None:\n",
        "      self.flag_vwt = False\n",
        "    elif self.vwt.ndim != 2:\n",
        "      raise ValueError('Time windows have to be a 2D array')\n",
        "    else:\n",
        "      self.flag_vwt = True\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "  def _filter_bank(self, X):\n",
        "    \"\"\"\n",
        "    Filter bank Characterization.\n",
        "    INPUT\n",
        "    -----\n",
        "      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
        "    OUTPUT\n",
        "    ------\n",
        "      1. X_f: (4D array) set of filtered EEG signals, shape (trials, channels, time_samples, frequency_bands)\n",
        "    \"\"\"\n",
        "    X_f = np.zeros((X.shape[0], X.shape[1], X.shape[2], self.f_bank.shape[0])) #epochs, Ch, Time, bands\n",
        "    for f in np.arange(self.f_bank.shape[0]):\n",
        "      X_f[:,:,:,f] = butterworth_digital_filter(X, N=5, Wn=self.f_bank[f], btype='bandpass', fs=self.sfreq)\n",
        "    return X_f\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "  def _sliding_windows(self, X):\n",
        "    \"\"\"\n",
        "    Sliding Windows Characterization.\n",
        "    INPUT\n",
        "    -----\n",
        "      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
        "    OUTPUT\n",
        "    ------\n",
        "      1. X_w: (4D array) shape (trials, channels, window_time_samples, number_of_windows)\n",
        "    \"\"\"\n",
        "    window_lenght = int(self.sfreq*self.vwt[0,1] - self.sfreq*self.vwt[0,0])\n",
        "    X_w = np.zeros((X.shape[0], X.shape[1], window_lenght, self.vwt.shape[0]))\n",
        "    for w in np.arange(self.vwt.shape[0]):\n",
        "        X_w[:,:,:,w] = X[:,:,int(self.sfreq*self.vwt[w,0]):int(self.sfreq*self.vwt[w,1])]\n",
        "    return X_w\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "  def fit(self, X, y=None):\n",
        "    \"\"\"\n",
        "    fit.\n",
        "    INPUT\n",
        "    -----\n",
        "      1. X: (3D array) set of EEG signals, shape (trials, channels, time_samples)\n",
        "      2. y: (1D array) target labels. Default=None\n",
        "    OUTPUT\n",
        "    ------\n",
        "      1. None\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "  def transform(self, X, y=None):\n",
        "    \"\"\"\n",
        "    Time frequency representation of EEG signals.\n",
        "    INPUT\n",
        "    -----\n",
        "      1. X: (3D array) set of EEG signals, shape (trials, channels, times)\n",
        "    OUTPUT\n",
        "    ------\n",
        "      1. X_wf: (5D array) Time-frequency representation of EEG signals, shape (trials, channels, window_time_samples, number_of_windows, frequency_bands)\n",
        "    \"\"\"\n",
        "    self._validation_param()     #Validate sfreq, f_freq, vwt\n",
        "\n",
        "    #Avoid edge effects of digital filter, 1st:fbk, 2th:vwt\n",
        "    if self.flag_f_bank:\n",
        "        X_f = self._filter_bank(X)\n",
        "    else:\n",
        "        X_f = X[:,:,:,np.newaxis]\n",
        "\n",
        "    if self.flag_vwt:\n",
        "      X_wf = []\n",
        "      for f in range(X_f.shape[3]):\n",
        "        X_wf.append(self._sliding_windows(X_f[:,:,:,f]))\n",
        "      X_wf = np.stack(X_wf, axis=-1)\n",
        "    else:\n",
        "      X_wf = X_f[:,:,:,np.newaxis,:]\n",
        "\n",
        "    return X_wf\n",
        "\n",
        "#plot eeg\n",
        "def plot_eeg(X,tv,ax,channels,esp=2,title=None):\n",
        "    # X in CH x Samples\n",
        "    n_canales = X.shape[0]\n",
        "\n",
        "    for ch in range(n_canales): # canales\n",
        "            xx = X[ch]\n",
        "            xx = xx - np.mean(xx)\n",
        "            xx = xx/np.max(abs(xx))\n",
        "            ax.plot(tv, xx +(ch * esp), label=channels[ch])  # Desplazamos cada canal para visualización\n",
        "    ax.set_yticks(range(0, esp * n_canales, esp), channels)  # Etiquetas en el eje Y\n",
        "    ax.set_xlabel(\"Tiempo [s]\")\n",
        "    ax.set_ylabel(\"Canales EEG [$\\mu$V]\")\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True)\n",
        "    ax.set_xlim([min(tv)-0.01,max(tv)+0.01])\n",
        "    ax.set_ylim([-esp,n_canales*esp+0.01])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:12.845729Z",
          "iopub.execute_input": "2025-12-12T23:30:12.846247Z",
          "iopub.status.idle": "2025-12-12T23:30:12.867642Z",
          "shell.execute_reply.started": "2025-12-12T23:30:12.846194Z",
          "shell.execute_reply": "2025-12-12T23:30:12.866341Z"
        },
        "id": "r0RjWSR_Zq0u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Establecemos el protocolo de pruebas y la configuración del montaje EEG\n",
        "\n",
        "Describir el protocolo de captura de datos y el montaje utilizado\n",
        "\n",
        "\n",
        "![mi](https://www.mdpi.com/diagnostics/diagnostics-13-01122/article_deploy/html/images/diagnostics-13-01122-g001.png)\n",
        "![montaje](https://www.mdpi.com/applsci/applsci-14-11208/article_deploy/html/images/applsci-14-11208-g001.png)"
      ],
      "metadata": {
        "id": "mFjt7xOWZq0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "channels = ['Fp1','Fpz','Fp2',\n",
        "            'AF7','AF3','AFz','AF4','AF8',\n",
        "            'F7','F5','F3','F1','Fz','F2','F4','F6','F8',\n",
        "            'FT7','FC5','FC3','FC1','FCz','FC2','FC4','FC6','FT8',\n",
        "            'T7','C5','C3','C1','Cz','C2','C4','C6','T8',\n",
        "            'TP7','CP5','CP3','CP1','CPz','CP2','CP4','CP6','TP8',\n",
        "            'P9','P7','P5','P3','P1','Pz','P2','P4','P6','P8','P10',\n",
        "            'PO7','PO3','POz','PO4','PO8',\n",
        "            'O1','Oz','O2',\n",
        "            'Iz']\n",
        "\n",
        "areas = {\n",
        "    'Frontal': ['Fpz', 'AFz', 'Fz', 'FCz'],\n",
        "    'Frontal Right': ['Fp2','AF4','AF8','F2','F4','F6','F8',],\n",
        "    'Central Right': ['FC2','FC4','FC6','FT8','C2','C4','C6','T8','CP2','CP4','CP6','TP8',],\n",
        "    'Posterior Right': ['P2','P4','P6','P8','P10','PO4','PO8','O2',],\n",
        "    #'Central': ['Cz'],\n",
        "    'Posterior': ['CPz','Pz', 'Cz','POz','Oz','Iz',],\n",
        "    'Posterior Left': ['P1','P3','P5','P7','P9','PO3','PO7','O1',],\n",
        "    'Central Left': ['FC1','FC3','FC5','FT7','C1','C3','C5','T7','CP1','CP3','CP5','TP7',],\n",
        "    'Frontal Left': ['Fp1','AF3','AF7','F1','F3','F5','F7',],\n",
        "}\n",
        "\n",
        "arcs = [\n",
        "    #'hemispheres',\n",
        "    'areas',\n",
        "    'channels',\n",
        "]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:12.869746Z",
          "iopub.execute_input": "2025-12-12T23:30:12.870113Z",
          "iopub.status.idle": "2025-12-12T23:30:12.895033Z",
          "shell.execute_reply.started": "2025-12-12T23:30:12.870086Z",
          "shell.execute_reply": "2025-12-12T23:30:12.893686Z"
        },
        "id": "KlTmpm_OZq0v"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definimos la ruta y los argumentos para la carga de los datos de EEG"
      ],
      "metadata": {
        "id": "6JLdAraHZq0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = GIGA_MI_ME('/kaggle/input/giga-science-gcpds/GIGA_MI_ME')\n",
        "#ti = 0\n",
        "#tf = 7\n",
        "new_fs = 256.\n",
        "load_args = dict(db = db,\n",
        "                 eeg_ch_names = channels,\n",
        "                 fs = db.metadata['sampling_rate'],\n",
        "                 #f_bank = np.asarray([[4., 40.]]),\n",
        "                 #vwt = np.asarray([[ti, tf]]), #2.5 - 5 MI\n",
        "                 new_fs = new_fs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:12.896384Z",
          "iopub.execute_input": "2025-12-12T23:30:12.896704Z",
          "iopub.status.idle": "2025-12-12T23:30:12.916522Z",
          "shell.execute_reply.started": "2025-12-12T23:30:12.896673Z",
          "shell.execute_reply": "2025-12-12T23:30:12.915339Z"
        },
        "id": "No3d1STxZq0w"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargamos los datos según el sujeto que se quiera"
      ],
      "metadata": {
        "id": "d2vpHPhAZq0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si se quiere cargar los datos de todos los sujetos, aplicar un ciclo que itere la lista de sujetos y de esta forma se cargara uno por uno dependiendo lo que se desee realizar.\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "for i in sbj:\n",
        "    X, y = load_GIGA(sbj=sbj, **load_args)"
      ],
      "metadata": {
        "id": "gLkB93dPZq0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sbj = 5\n",
        "X, y = load_GIGA(sbj=sbj, **load_args)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:12.917875Z",
          "iopub.execute_input": "2025-12-12T23:30:12.918275Z",
          "iopub.status.idle": "2025-12-12T23:30:18.464016Z",
          "shell.execute_reply.started": "2025-12-12T23:30:12.918206Z",
          "shell.execute_reply": "2025-12-12T23:30:18.462812Z"
        },
        "id": "Ex-fuhi_Zq0w"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X con {X.shape[0]} intentos; {X.shape[1]} canales; {X.shape[2]} muestras No. de segundos {X.shape[2]/new_fs}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:18.465193Z",
          "iopub.execute_input": "2025-12-12T23:30:18.465557Z",
          "iopub.status.idle": "2025-12-12T23:30:18.470971Z",
          "shell.execute_reply.started": "2025-12-12T23:30:18.465532Z",
          "shell.execute_reply": "2025-12-12T23:30:18.469867Z"
        },
        "id": "XT-a8Qi7Zq0x"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:18.4723Z",
          "iopub.execute_input": "2025-12-12T23:30:18.472611Z",
          "iopub.status.idle": "2025-12-12T23:30:18.492614Z",
          "shell.execute_reply.started": "2025-12-12T23:30:18.47258Z",
          "shell.execute_reply": "2025-12-12T23:30:18.491667Z"
        },
        "id": "6fRKzFhrZq0x"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización de las señales de EEG en el tiempo"
      ],
      "metadata": {
        "id": "oAcNRNHxZq0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#graficar canales promedio\n",
        "trial = 0\n",
        "ti = 0 # ti\n",
        "tf = 7 # tf\n",
        "tv = np.arange(ti,tf,1/new_fs)\n",
        "\n",
        "#Señal cruda\n",
        "fig,ax = plt.subplots(1,1,figsize=(8,8),sharex = True)\n",
        "# Graficar cada canal en un subplot banda respectiva\n",
        "\n",
        "plot_eeg(X[trial],tv,ax=ax,channels=channels,title='EEG original')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:18.495605Z",
          "iopub.execute_input": "2025-12-12T23:30:18.495901Z",
          "iopub.status.idle": "2025-12-12T23:30:19.440747Z",
          "shell.execute_reply.started": "2025-12-12T23:30:18.495876Z",
          "shell.execute_reply": "2025-12-12T23:30:19.43963Z"
        },
        "id": "jvfQ6OZzZq0y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 2\n",
        "\n",
        "Discuta la gráfica anterior\n",
        "**DISCUCION DE LA GRAFICA**\n",
        "\n",
        "**Análisis de la Gráfica EEG en relación con los Ritmos Cerebrales**\n",
        "La gráfica representa señales EEG multicanal en microvoltios (µV) vs. tiempo (s). Se observan múltiples trazas correspondientes a distintos electrodos ubicados en el cuero cabelludo, que registran la actividad eléctrica del cerebro.\n",
        "\n",
        "A continuación, discutimos cómo se pueden relacionar los patrones observados con los ritmos cerebrales principales: delta, theta, alpha, beta y gamma.\n",
        "\n",
        "*  La gráfica muestra múltiples canales EEG con oscilaciones características de la actividad cerebral.\n",
        " * Sin un análisis espectral (FFT o Wavelet), no podemos determinar con certeza qué ritmos predominan.\n",
        "* Según la forma de las señales, podríamos suponer que hay actividad en los rangos de Alpha y Beta, y quizás Theta.\n",
        "* Si el sujeto estaba relajado, esperaríamos Alpha; si estaba atento o realizando una tarea cognitiva, esperaríamos Beta.\n",
        "* Para confirmar cada tipo de ritmo, debemos aplicar filtros de frecuencia específicos y realizar un análisis de espectro.\n"
      ],
      "metadata": {
        "id": "mV2OVOlRZq0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: Discuta en qué consisten los ritmos cerebrales\n",
        "\n",
        "![montaje](https://cdn.shopify.com/s/files/1/0348/7053/files/storage.googleapis.com-486681944373284_61cb9936-f6c2-493d-8402-3426d7f5a049_1024x1024.jpg?v=1689309340)\n",
        "\n"
      ],
      "metadata": {
        "id": "zQPSANZyZq0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filtramos trials completos en ritmos cerebrales utilizando filtros IIR\n",
        "\n",
        "\n",
        "f_bank = np.array([[0.5,4.],[4., 8.],[8.,13.],[13.,32.],[32.,100.]])\n",
        "vwt = np.asarray([[ti, tf]]) #2.5 - 5 MI 0 - 7 trial completo\n",
        "tf_repr = TimeFrequencyRpr(sfreq = new_fs, f_bank = f_bank)\n",
        "\n",
        "Xrc = np.squeeze(tf_repr.transform(X))\n",
        "\n",
        "Xrc.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:19.443199Z",
          "iopub.execute_input": "2025-12-12T23:30:19.443598Z",
          "iopub.status.idle": "2025-12-12T23:30:24.662448Z",
          "shell.execute_reply.started": "2025-12-12T23:30:19.443565Z",
          "shell.execute_reply": "2025-12-12T23:30:24.661348Z"
        },
        "id": "SbvYUxzDZq0y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 3\n",
        "\n",
        "Expliqué cómo se calcularon cada una de las 5 dimensiones del arreglo Xrc"
      ],
      "metadata": {
        "id": "l-n99AOQZq0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solucion**\n",
        "\n",
        "**1** primero se define la banda de frecuencias a filtrar:\n",
        "Se establece un banco de filtros (f_bank) con 5 bandas de frecuencia correspondientes a los ritmos cerebrales principales:\n",
        "\n",
        "f_bank = np.array([\n",
        "    [0.5, 4.],    # Delta\n",
        "    [4., 8.],     # Theta\n",
        "    [8., 13.],    # Alpha\n",
        "    [13., 32.],   # Beta\n",
        "    [32., 100.]   # Gamma\n",
        "])\n",
        "estas bandas permiten separar la señal en diefrentes componentes.\n",
        "\n",
        "**2**Definir la ventana de tiempo (vwt)\n",
        "Se extrae un segmento específico de la señal EEG, por ejemplo, de 2.5 a 5 segundos para movimiento imaginado (MI) o de 0 a 7 segundos para un trial completo:\n",
        "\n",
        "vwt = np.asarray([[ti, tf]])\n",
        "\n",
        "**3**Aplicar la transformación de dominio tiempo-frecuencia\n",
        "TimeFrequencyRpr (posiblemente basado en MNE o Braindecode) toma la señal EEG, filtra cada banda de frecuencia y genera una representación tiempo-frecuencia.\n",
        "\n",
        "tf_repr = TimeFrequencyRpr(sfreq=new_fs, f_bank=f_bank)\n",
        "\n",
        "**4**Transformar los datos EEG\n",
        "La transformación filtra los datos y obtiene una nueva representación con las 5 dimensiones del arreglo Xrc:\n",
        "\n",
        "Xrc = np.squeeze(tf_repr.transform(X))\n",
        "\n",
        "**Relación con el Procesamiento de EEG**\n",
        "Cada una de estas dimensiones tiene una utilidad específica en el análisis EEG:\n",
        "\n",
        "* Separar ensayos EEG (dim 1) → Para analizar respuestas en diferentes sujetos o repeticiones.\n",
        "* Filtrar por electrodos (dim 2) → Permite identificar actividad en diferentes regiones del cerebro.\n",
        "* Separar bandas de frecuencia (dim 3) → Analiza cómo los ritmos cerebrales cambian en el tiempo.\n",
        "* Observar evolución temporal (dim 4) → Permite analizar cambios en la actividad cerebral en diferentes momentos.\n",
        "* Convertir la señal a frecuencia (dim 5) → Permite aplicar algoritmos de clasificación o análisis espectral.\n",
        "\n",
        "**Conclusiónes**\n",
        "El proceso convierte la señal EEG en una representación tiempo-frecuencia multibanda, donde:\n",
        "\n",
        "* Cada ensayo EEG se divide en canales.\n",
        "* Cada canal se filtra en 5 bandas de frecuencia (ritmos cerebrales).\n",
        "* Cada banda se transforma en coeficientes tiempo-frecuencia.\n"
      ],
      "metadata": {
        "id": "Dr2RUMaKZq0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ritmo = ['delta','theta','alpha','beta','gamma']\n",
        "trial = 0\n",
        "n_trials, n_canales, n_muestras, n_bands = Xrc.shape  # Simulación de datos\n",
        "\n",
        "esp = 2 #espaciado canales\n",
        "fig,ax = plt.subplots(5,1,figsize=(8,40))\n",
        "# Graficar cada canal en un subplot banda respectiva\n",
        "for b in range(f_bank.shape[0]): #bandas\n",
        "    plot_eeg(Xrc[trial,:,:,b],tv,ax=ax[b],channels=channels,title=f'EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]}')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:24.66319Z",
          "iopub.execute_input": "2025-12-12T23:30:24.663488Z",
          "iopub.status.idle": "2025-12-12T23:30:28.452568Z",
          "shell.execute_reply.started": "2025-12-12T23:30:24.663465Z",
          "shell.execute_reply": "2025-12-12T23:30:28.451327Z"
        },
        "id": "oJcsHWLgZq0z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización de las señales de EEG en la frecuencia"
      ],
      "metadata": {
        "id": "1b4eFIheZq0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#señal orignal\n",
        "Xwo = np.fft.rfft(X,axis=-1)\n",
        "vfreq = np.fft.rfftfreq(X.shape[2],1/new_fs)\n",
        "\n",
        "Xwo.shape\n",
        "plt.plot(vfreq,20*np.log10(np.abs(Xwo[trial])).T)\n",
        "plt.xlabel('Frecuencia [Hz]')\n",
        "plt.ylabel('Magnitud [dB]')\n",
        "plt.title('Eespectro Señal EEG original')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:28.453686Z",
          "iopub.execute_input": "2025-12-12T23:30:28.453997Z",
          "iopub.status.idle": "2025-12-12T23:30:28.951396Z",
          "shell.execute_reply.started": "2025-12-12T23:30:28.45397Z",
          "shell.execute_reply": "2025-12-12T23:30:28.95013Z"
        },
        "id": "JdHKi7CGZq00"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 4\n",
        "\n",
        "Discuta la gráfica anterior"
      ],
      "metadata": {
        "id": "OFVdEYr5Zq00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solucion**\n",
        "\n",
        "La gráfica muestra el espectro de frecuencia de varias señales EEG, mostrando cómo la energía de cada una de las señales se distribuye en diferentes frecuencias. Se observa la magnitud en decibeles (dB) vs. frecuencia en Hertz (Hz).\n",
        "\n",
        "**1** **Descripción General de la Gráfica**\n",
        "* Eje X (Frecuencia en Hz): Representa la frecuencia de la señal EEG, cubriendo un rango aproximado de 0 a 125 Hz.\n",
        "* Eje Y (Magnitud en dB): Indica la intensidad de la señal en cada frecuencia.\n",
        "* Múltiples colores: Pueden representar diferentes canales EEG o múltiples ensayos (trials).\n",
        "\n",
        "**2. Características Notables en la Gráfica**\n",
        "a) Predominio de Energía en Frecuencias Bajas (0-20 Hz)\n",
        "Se observa un pico de alta energía en frecuencias bajas (cercanas a 0 Hz), lo que es típico en señales EEG.\n",
        "La mayor parte de la actividad EEG se concentra en el rango 0-20 Hz, lo que concuerda con la presencia de ritmos cerebrales como:\n",
        "\n",
        "* Delta (0.5-4 Hz) → Relacionado con sueño profundo.\n",
        "* Theta (4-8 Hz) → Asociado con relajación y somnolencia.\n",
        "* Alpha (8-13 Hz) → Presente en estados de calma y ojos cerrados.\n",
        "* Beta (13-30 Hz) → Relacionado con actividad mental y concentración.\n",
        "\n",
        "Este patrón es esperado en EEG, ya que la actividad cerebral relevante ocurre principalmente en frecuencias bajas.\n",
        "\n",
        "**b) Presencia de Ruido en Frecuencias Altas (>30 Hz)**\n",
        "A partir de 30 Hz, la magnitud disminuye, pero sigue habiendo bastante ruido.\n",
        "Este rango incluye ondas Gamma (30-100 Hz), que están asociadas con procesamiento cognitivo avanzado.\n",
        "Sin embargo, la dispersión de energía en frecuencias altas sugiere la presencia de ruido electromagnético o muscular.\n",
        "\n",
        "El EEG es sensible a interferencias, y el ruido de alta frecuencia puede deberse a:\n",
        "\n",
        "* Ruido muscular (EMG): Movimientos faciales, parpadeos.\n",
        "* Interferencias de red eléctrica (50/60 Hz): Se observa un pico alrededor de 60 Hz, lo que sugiere interferencia.\n",
        "* Artefactos electrónicos: Equipos en el entorno pueden introducir ruido en estas frecuencias.\n",
        "\n",
        "**3. Mejoras Posibles en el Procesamiento de la Señal EEG**\n",
        "Para mejorar la calidad de la señal y eliminar el ruido, se pueden aplicar técnicas de procesamiento:\n",
        "\n",
        "* Filtrado Paso Bajo (<40 Hz):\n",
        "\n",
        "Ayudaría a eliminar el ruido de alta frecuencia y aislar los ritmos cerebrales más relevantes.\n",
        "\n",
        "* Filtrado Notch en 60 Hz:\n",
        "\n",
        "Útil para eliminar interferencia de la red eléctrica.\n",
        "\n",
        "* Filtrado de Bandas Específicas (IIR o FIR):\n",
        "\n",
        "Permitiría aislar ritmos específicos (Delta, Theta, Alpha, Beta, Gamma).\n",
        "\n",
        "* Análisis Tiempo-Frecuencia (Wavelet Transform o STFT):\n",
        "\n",
        "Mejoraría la interpretación al permitir analizar cómo cambian las frecuencias en el tiempo."
      ],
      "metadata": {
        "id": "RUDtnLIBZq00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#espectro señales filtradas\n",
        "Xwb = np.fft.rfft(Xrc,axis=2)\n",
        "\n",
        "Xwb.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:28.952197Z",
          "iopub.execute_input": "2025-12-12T23:30:28.952502Z",
          "iopub.status.idle": "2025-12-12T23:30:30.00279Z",
          "shell.execute_reply.started": "2025-12-12T23:30:28.952479Z",
          "shell.execute_reply": "2025-12-12T23:30:30.001744Z"
        },
        "id": "iLgZbeIdZq00"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#espectro señales filtradas por bandas - ritmos cerebrales\n",
        "\n",
        "fig,ax = plt.subplots(5,1,figsize=(8,40))\n",
        "# Graficar cada canal en un subplot banda respectiva\n",
        "for b in range(f_bank.shape[0]): #bandas\n",
        "    ax[b].plot(vfreq,20*np.log10(np.abs(Xwb[trial,:,:,b])).T)\n",
        "    ax[b].set_xlabel('Frecuencia [Hz]')\n",
        "    ax[b].set_ylabel('Magnitud [dB]')\n",
        "    ax[b].set_title(f'Esepctro EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]}')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:30.003835Z",
          "iopub.execute_input": "2025-12-12T23:30:30.004264Z",
          "iopub.status.idle": "2025-12-12T23:30:31.8856Z",
          "shell.execute_reply.started": "2025-12-12T23:30:30.004205Z",
          "shell.execute_reply": "2025-12-12T23:30:31.884566Z"
        },
        "id": "h3kU1joDZq01"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 5\n",
        "\n",
        "Discuta las gráficas"
      ],
      "metadata": {
        "id": "JuXG8siwZq01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**solucion**\n",
        "\n",
        "Las gráficas muestran del espectro de una señal EEG después de aplicar filtros en diferentes bandas de frecuencia correspondientes a los ritmos cerebrales Delta, Theta, Alpha, Beta y Gamma. vamos a analizar cada grafico basadops en la actividad cerebral.\n",
        "\n",
        "* Eje X (Frecuencia en Hz): Muestra el rango de frecuencias analizadas.\n",
        "* Eje Y (Magnitud en dB): Representa la potencia de la señal EEG en cada frecuencia.\n",
        "* Múltiples colores: Representan diferentes canales EEG o  en otro caso múltiples ensayos.\n",
        "* Cada gráfico ha sido filtrado en una banda específica de frecuencia, aislando un ritmo cerebral de interes para nosotros.\n",
        "\n",
        "\n",
        "**Espectro EEG Filtrado en 0.5 - 4.0 Hz (Ritmo Delta)**\n",
        "\n",
        "* Dominancia de frecuencias muy bajas (0.5 - 4 Hz), con una caída progresiva en las frecuencias más altas.\n",
        "* Alta magnitud en la banda baja, lo cual es típico de ondas Delta.\n",
        "* Estas ondas son características del sueño profundo y estados inconscientes.\n",
        "\n",
        "**Espectro EEG Filtrado en 4.0 - 8.0 Hz (Ritmo Theta)**\n",
        "\n",
        "* Se observa un pico claro en el rango de 4-8 Hz, con una disminución progresiva hacia las frecuencias más altas.\n",
        "* Este ritmo está relacionado con estados de relajación, y meditacion.\n",
        "* Se observa menos energía en comparación con Delta, pero aún con una presencia significativa.\n",
        "\n",
        "**Espectro EEG Filtrado en 8.0 - 13.0 Hz (Ritmo Alpha)**\n",
        "\n",
        "* Aparece un pico claro en la banda Alpha (8-13 Hz).\n",
        "* Las ondas Alpha son más fuertes cuando una persona está relajada pero despierta, especialmente con los ojos cerrados.\n",
        "* Esta actividad suele predominar en el lóbulo occipital y parietal.\n",
        "  \n",
        "**Espectro EEG Filtrado en 13.0 - 32.0 Hz (Ritmo Beta)**\n",
        "\n",
        "* Se observa un pico en la banda Beta (13-32 Hz), con alta actividad en esta región.\n",
        "* Las ondas Beta están relacionadas con actividad mental, atención, concentración y procesamiento sensorial.\n",
        "* La caída en frecuencias altas sugiere pérdida de energía debido al filtrado.\n",
        "\n",
        "\n",
        "**Espectro EEG Filtrado en 32.0 - 100.0 Hz (Ritmo Gamma)**\n",
        "\n",
        "* Amplia presencia de actividad en el rango Gamma (32-100 Hz).\n",
        "* Se observa una distribución uniforme de energia en la banda.\n",
        "* Las ondas Gamma están relacionadas con procesos cognitivos avanzados, memoria de trabajo y percepción sensorial.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hkHYbs21Zq01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización de espectrogramas\n",
        "\n",
        "Consultar qué es la Short Time Fourier Transform\n",
        "\n"
      ],
      "metadata": {
        "id": "elLCg9YMZq01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\n",
        "from scipy.signal import stft #\n",
        "nperseg = 0.5*new_fs#longitud ventas en muestras\n",
        "vfs,t,Xstft = stft(X,fs=new_fs,nperseg=nperseg,axis=2)\n",
        "Xstft = 20*np.log10(abs(Xstft))\n",
        "\n",
        "#graficar stft para un trial y un canal\n",
        "trail = 0\n",
        "chi = channels.index('C4')\n",
        "\n",
        "fig, ax = plt.subplots(2, 1,figsize=(10,6))\n",
        "\n",
        "ax[1].plot(tv,X[trail,chi,:])\n",
        "ax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\n",
        "im = ax[0].pcolormesh(t, vfs, Xstft[trail,chi])\n",
        "fig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\n",
        "plt.gca()\n",
        "plt.xlabel('t [seg]')\n",
        "plt.ylabel('f [Hz]')\n",
        "ax[0].set_title(f'Esepctrograma EEG Original -- Ch = {channels[chi]}')\n",
        "print(Xstft.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:31.886478Z",
          "iopub.execute_input": "2025-12-12T23:30:31.886762Z",
          "iopub.status.idle": "2025-12-12T23:30:33.687258Z",
          "shell.execute_reply.started": "2025-12-12T23:30:31.886738Z",
          "shell.execute_reply": "2025-12-12T23:30:33.686184Z"
        },
        "id": "FolCcibuZq02"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#estimar stft con ventanas de nperseg puntos sobre eje temporal en EEG original\n",
        "b = 2\n",
        "vfs,t,Xstftb = stft(Xrc,fs=new_fs,nperseg=nperseg,axis=2)\n",
        "Xstftb = 20*np.log10(abs(Xstftb))\n",
        "\n",
        "print(Xstftb.shape)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(2, 1,figsize=(10,6))\n",
        "ax[1].plot(tv,Xrc[trail,chi,:,b])\n",
        "ax[1].set_ylabel(\"Amp. [$\\mu$ V]\")\n",
        "im = ax[0].pcolormesh(t, vfs, Xstftb[trail,chi,:,b,:])\n",
        "fig.colorbar(im, ax=ax[0],orientation=\"horizontal\",pad=0.2)\n",
        "plt.gca()\n",
        "plt.xlabel('t [seg]')\n",
        "plt.ylabel('f [Hz]')\n",
        "ax[0].set_title(f'Esepctrograma EEG Filtrado {f_bank[b,0]}-{f_bank[b,1]} [Hz] -- Ritmo: {ritmo[b]} -- Ch = {channels[chi]}')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:33.688318Z",
          "iopub.execute_input": "2025-12-12T23:30:33.688671Z",
          "iopub.status.idle": "2025-12-12T23:30:40.518516Z",
          "shell.execute_reply.started": "2025-12-12T23:30:33.688639Z",
          "shell.execute_reply": "2025-12-12T23:30:40.517329Z"
        },
        "id": "MNpcmOYDZq02"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 6\n",
        "\n",
        "Presente las gráficas de stft para distintos canales en los 5 ritmos cerebrales y discuta."
      ],
      "metadata": {
        "id": "GyrPEjLBZq02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import stft\n",
        "\n",
        "# Nombre de los ritmos cerebrales\n",
        "ritmo = ['delta','theta','alpha','beta','gamma']\n",
        "\n",
        "# Elegimos un trial de ejemplo\n",
        "trial = 0\n",
        "\n",
        "# Canales que queremos visualizar\n",
        "channels_to_plot = ['C3', 'C4', 'O1', 'O2']  # Prueba de canales\n",
        "\n",
        "# Ventana STFT de 0.5 segundos (puedes ajustarla a tu gusto)\n",
        "nperseg = int(0.5 * new_fs)\n",
        "\n",
        "for ch_name in channels_to_plot:\n",
        "    # Índice del canal en tu lista 'channels'\n",
        "    ch_idx = channels.index(ch_name)\n",
        "\n",
        "    # Creamos una figura con 5 subplots (uno por cada banda)\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(20,4))\n",
        "\n",
        "    for b in range(5):\n",
        "        # Obtenemos la señal ya filtrada en la banda 'b' para el canal 'ch_idx' y trial seleccionado\n",
        "        signal_band = Xrc[trial, ch_idx, :, b]\n",
        "\n",
        "        # Calculamos la STFT\n",
        "        f, t, Zxx = stft(signal_band, fs=new_fs, nperseg=nperseg)\n",
        "\n",
        "        # Convertimos magnitud a dB (añadiendo un offset para evitar log(0))\n",
        "        Zxx_db = 20 * np.log10(np.abs(Zxx) + 1e-16)\n",
        "\n",
        "        # Graficamos el espectrograma con pcolormesh\n",
        "        im = axs[b].pcolormesh(t, f, Zxx_db, shading='gouraud', cmap='jet')\n",
        "\n",
        "        axs[b].set_title(f'Canal: {ch_name}\\nRitmo: {ritmo[b]}')\n",
        "        axs[b].set_xlabel('Tiempo [s]')\n",
        "        axs[b].set_ylabel('Frecuencia [Hz]')\n",
        "\n",
        "        # Barra de color en cada subplot\n",
        "        plt.colorbar(im, ax=axs[b], orientation='vertical')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:40.519433Z",
          "iopub.execute_input": "2025-12-12T23:30:40.519709Z",
          "iopub.status.idle": "2025-12-12T23:30:47.52763Z",
          "shell.execute_reply.started": "2025-12-12T23:30:40.519686Z",
          "shell.execute_reply": "2025-12-12T23:30:47.526331Z"
        },
        "id": "SWTXxXjBZq0-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discucion de las graficas**\n",
        "Cada señal se puede mostrar como evoluciona a travez del tiempo, por ejemplo si se observa un incremento en la potencia alpha en un momento determinado, podria estar en un estado de relaajacion.\n",
        "En algunos momentos y frecuencias, podrían verse “picos” o bandas de alta energía que no correspondan a actividad cerebral sino a artefactos de parpadeo, movimiento muscular, ruido de línea (50/60 Hz), etc.\n",
        "En resumen, estas gráficas STFT brindan una vista detallada de cómo la potencia de la señal EEG varía en el tiempo y en frecuencia. Esto permite:\n",
        "\n",
        "Identificar bandas relevantes para tu estudio,por ejemplo alpha en occipital, beta en canales centrales.\n",
        "Reconocer la presencia de artefactos.\n",
        "Relacionar la actividad cerebral con eventos experimentales.\n",
        "Observar diferencias entre canales y entre sujetos."
      ],
      "metadata": {
        "id": "sQUDmQhwZq0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización de señales EEG sobre montaje 10-20"
      ],
      "metadata": {
        "id": "APUdxXBRZq0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "\n",
        "# Cargar el montaje estándar\n",
        "easycap_montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
        "\n",
        "\n",
        "# Crear un montaje personalizado con los electrodos seleccionados\n",
        "custom_pos = {ch: easycap_montage.get_positions()[\"ch_pos\"][ch] for ch in channels}\n",
        "custom_montage = mne.channels.make_dig_montage(ch_pos=custom_pos, coord_frame=\"head\")\n",
        "\n",
        "# Mostrar el montaje personalizado\n",
        "custom_montage.plot(show_names=True)\n",
        "fig = custom_montage.plot(kind=\"3d\", show_names=True, show=False)\n",
        "fig.gca().view_init(azim=70, elev=15)  # Ajustar la vista 3D"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:47.528772Z",
          "iopub.execute_input": "2025-12-12T23:30:47.529069Z",
          "iopub.status.idle": "2025-12-12T23:30:48.286985Z",
          "shell.execute_reply.started": "2025-12-12T23:30:47.529045Z",
          "shell.execute_reply": "2025-12-12T23:30:48.285687Z"
        },
        "id": "1lt4rRI2Zq0_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:48.288239Z",
          "iopub.execute_input": "2025-12-12T23:30:48.288559Z",
          "iopub.status.idle": "2025-12-12T23:30:58.37306Z",
          "shell.execute_reply.started": "2025-12-12T23:30:48.288525Z",
          "shell.execute_reply": "2025-12-12T23:30:58.371692Z"
        },
        "scrolled": true,
        "id": "EK_sg3D7Zq0_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topomaps"
      ],
      "metadata": {
        "id": "E9_A1VFRZq0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gcpds.visualizations.topoplots import topoplot\n",
        "\n",
        "\n",
        "trial = 150\n",
        "vec_topo_o = abs(X[trial,:]).mean(axis=-1)\n",
        "vec_topo_b = abs(Xrc[trial,:,:,:]).mean(axis=1)\n",
        "\n",
        "\n",
        "fig,ax = plt.subplots(1,6,figsize=(20,10))\n",
        "topoplot(vec_topo_o, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[0],show=False,vlim=(min(vec_topo_o), max(vec_topo_o)))\n",
        "\n",
        "for b in range(f_bank.shape[0]):\n",
        "    vec_ = vec_topo_b[:,b]\n",
        "    topoplot(vec_, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[b+1],show=False,vlim=(min(vec_), max(vec_)))\n",
        "    ax[b+1].set_title(ritmo[b])\n",
        "\n",
        "ax[0].set_title(f'EEG-suj={sbj}-trial={trial}')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:30:58.374426Z",
          "iopub.execute_input": "2025-12-12T23:30:58.37474Z",
          "iopub.status.idle": "2025-12-12T23:31:00.219337Z",
          "shell.execute_reply.started": "2025-12-12T23:30:58.374712Z",
          "shell.execute_reply": "2025-12-12T23:31:00.218058Z"
        },
        "id": "UBBGAjd-Zq0_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 7\n",
        "\n",
        "Discuta"
      ],
      "metadata": {
        "id": "kXQ5nGw_Zq1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discucion de las graficas**\n",
        "\n",
        "Cada mapa topográfico representa la intensidad de la actividad EEG en cada ritmo cerebral, lo que nos permite analizar qué regiones del cerebro están más activas en un momento específico.\n",
        "\n",
        "🔴 **1. Gráfico de EEG Original**\n",
        "Muestra la actividad EEG sin filtrar, lo que significa que contiene información de todas las frecuencias.\n",
        "\n",
        "Se observan regiones con mayor actividad en la parte occipital y temporal, lo que podría estar relacionado con procesamiento visual o motor.\n",
        "\n",
        "🌑 **2. Ritmo Delta (0.5 - 4 Hz)**\n",
        "Actividad más prominente en regiones parietales y occipitales.\n",
        "\n",
        "Las ondas delta están asociadas con sueño profundo y estados de reposo.\n",
        "\n",
        "La baja actividad en la parte frontal sugiere que el sujeto no estaba en un estado de sueño profundo.\n",
        "\n",
        "🟠 3. Ritmo Theta (4 - 8 Hz)\n",
        "Mayor actividad en la parte frontal y temporal.\n",
        "\n",
        "Las ondas theta están relacionadas con relajación, memoria y procesamiento cognitivo.\n",
        "\n",
        "La alta intensidad en la parte superior sugiere que el sujeto podría estar en un estado de concentración o relajación profunda.\n",
        "\n",
        "🟡 4. Ritmo Alpha (8 - 13 Hz)\n",
        "Se observa alta actividad en la región occipital y parietal.\n",
        "\n",
        "Las ondas alpha son más intensas cuando una persona está relajada con los ojos cerrados.\n",
        "\n",
        "Si el sujeto estaba en reposo, este patrón es esperado y normal.\n",
        "\n",
        "🔴 5. Ritmo Beta (13 - 32 Hz)\n",
        "Alta actividad en las regiones frontales y temporales.\n",
        "\n",
        "Las ondas beta están relacionadas con concentración, actividad mental y procesamiento sensorial.\n",
        "\n",
        "Esto sugiere que el sujeto podría haber estado realizando una tarea cognitiva.\n",
        "\n",
        "🔴 6. Ritmo Gamma (32 - 100 Hz)\n",
        "Actividad distribuida en múltiples regiones, pero con puntos de alta intensidad.\n",
        "\n",
        "Las ondas gamma están asociadas con procesamiento cognitivo avanzado, memoria de trabajo y toma de decisiones.\n",
        "\n",
        "La presencia de actividad gamma sugiere que el sujeto podría haber estado en una tarea compleja o en un estado de atención alta."
      ],
      "metadata": {
        "id": "flCxJyRIZq1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Spatial Patterns\n",
        "\n",
        "Consulté qué son los Common Spatial Patterns (CSP) y su aplicación al procesado de señales EEG"
      ],
      "metadata": {
        "id": "crap8f-BZq1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "from mne.decoding import CSP\n",
        "\n",
        "# Instancia del objeto CSP\n",
        "n_components = 2\n",
        "csp = CSP(n_components=n_components, log= True, transform_into='average_power')\n",
        "# Ajuste y transformación de los datos\n",
        "csp_data = csp.fit_transform(X.astype(np.float64), y)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:31:00.220468Z",
          "iopub.execute_input": "2025-12-12T23:31:00.220751Z",
          "iopub.status.idle": "2025-12-12T23:31:03.963265Z",
          "shell.execute_reply.started": "2025-12-12T23:31:00.220727Z",
          "shell.execute_reply": "2025-12-12T23:31:03.962284Z"
        },
        "id": "Qqyctz2bZq1A"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CSP Transformado Shape:\", csp_data.shape)\n",
        "plt.scatter(csp_data[:,0],csp_data[:,1],c=y)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:31:03.964409Z",
          "iopub.execute_input": "2025-12-12T23:31:03.964796Z",
          "iopub.status.idle": "2025-12-12T23:31:04.127848Z",
          "shell.execute_reply.started": "2025-12-12T23:31:03.964759Z",
          "shell.execute_reply": "2025-12-12T23:31:04.126762Z"
        },
        "id": "SsqDrf4PZq1B"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#EEG original\n",
        "fig,ax = plt.subplots(1,n_components,figsize=(5,5))\n",
        "for cc in range(n_components):\n",
        "    vec_ = np.abs(csp.filters_[cc])\n",
        "    topoplot(vec_, channels, contours=3, cmap='Reds', names=channels, sensors=False,ax=ax[cc],show=False,vlim=(min(vec_), max(vec_)))\n",
        "    ax[cc].set_title(f'CSP {cc+1}')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:31:04.128975Z",
          "iopub.execute_input": "2025-12-12T23:31:04.129367Z",
          "iopub.status.idle": "2025-12-12T23:31:04.901472Z",
          "shell.execute_reply.started": "2025-12-12T23:31:04.129338Z",
          "shell.execute_reply": "2025-12-12T23:31:04.900466Z"
        },
        "id": "xgtlR3oXZq1B"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#lectura de datos\n",
        "sbj = 14\n",
        "X, y = load_GIGA(sbj=sbj, **load_args)\n",
        "\n",
        "f_bank = np.array([[0.5,4.],[4., 8.],[8.,13.],[13.,32.],[32.,100.]])\n",
        "vwt = np.array([[0.25, 1.75],[1.5,3],[2.75,4.25],[4,5.5],[5.25,6.75]]) #2.5 - 5 MI 0 - 7 trial completo\n",
        "tf_repr = TimeFrequencyRpr(sfreq = new_fs, f_bank = f_bank,vwt=vwt)\n",
        "X_ = np.squeeze(tf_repr.transform(X))\n",
        "X_.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:31:04.902455Z",
          "iopub.execute_input": "2025-12-12T23:31:04.90277Z",
          "iopub.status.idle": "2025-12-12T23:31:16.560612Z",
          "shell.execute_reply.started": "2025-12-12T23:31:04.902745Z",
          "shell.execute_reply": "2025-12-12T23:31:16.55965Z"
        },
        "id": "ZuruzvytZq1B"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# csp por ventanas y ritmos\n",
        "# Definir las dimensiones del arreglo\n",
        "ritmos_ = f_bank.shape[0]\n",
        "ventanas_ = vwt.shape[0]\n",
        "n_comp = 2\n",
        "# Inicializar el arreglo vacío con listas anidadas\n",
        "csp_M = [[None for _ in range(ventanas_)] for _ in range(ritmos_)]\n",
        "csp_filters_ = np.zeros((ritmos_,ventanas_,X_.shape[1],X_.shape[1])) #ritmos ventanas Ch\n",
        "Xcsp_ = np.zeros((X_.shape[0],n_comp,ritmos_,ventanas_))\n",
        "\n",
        "for i in range(ritmos_):\n",
        "    for j in range(ventanas_):\n",
        "        print(f'CSP ritmo {f_bank[i]} -- ventana {vwt[j]}...')\n",
        "        csp_M[i][j] =  CSP(n_components=n_comp, log= True, transform_into='average_power')\n",
        "        Xcsp_[:,:,i,j] = csp.fit_transform(X_[:,:,:,j,i].astype(np.float64), y)\n",
        "        csp_filters_[i,j,:] = np.abs(csp.filters_)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:31:16.56163Z",
          "iopub.execute_input": "2025-12-12T23:31:16.562024Z",
          "iopub.status.idle": "2025-12-12T23:31:23.859342Z",
          "shell.execute_reply.started": "2025-12-12T23:31:16.561988Z",
          "shell.execute_reply": "2025-12-12T23:31:23.858083Z"
        },
        "id": "zB-ukdtJZq1C"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# graficar topomaps\n",
        "fig, ax = plt.subplots(ritmos_,ventanas_,figsize=(12,12))\n",
        "\n",
        "for i in range(ritmos_):\n",
        "    for j in range(ventanas_):\n",
        "        vec_ = csp_filters_[i,j,0]\n",
        "        vec_ = vec_/max(vec_)\n",
        "        topoplot(vec_, channels, contours=3, cmap='Reds', names=None, sensors=False,ax=ax[i,j],show=False,vlim=(min(vec_), max(vec_)))\n",
        "    ax[i,0].set_ylabel(ritmo[i],fontsize=20)\n",
        "for j in range(ventanas_):\n",
        "     ax[0,j].set_title(f'{vwt[j,0]}--{vwt[j,1]} [s]',fontsize=15)\n",
        "\n",
        "plt.subplots_adjust(hspace=-0.025,wspace=-0.025)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:31:23.860453Z",
          "iopub.execute_input": "2025-12-12T23:31:23.860838Z",
          "iopub.status.idle": "2025-12-12T23:31:27.685398Z",
          "shell.execute_reply.started": "2025-12-12T23:31:23.860803Z",
          "shell.execute_reply": "2025-12-12T23:31:27.684012Z"
        },
        "id": "uk_puydtZq1C"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#scatters\n",
        "fig, ax = plt.subplots(ritmos_,ventanas_,figsize=(12,12))\n",
        "\n",
        "for i in range(ritmos_):\n",
        "    for j in range(ventanas_):\n",
        "        ax[i,j].scatter(Xcsp_[:,0,i,j],Xcsp_[:,1,i,j],c=y)\n",
        "        ax[i,j].set_xticks([])\n",
        "        ax[i,j].set_yticks([])\n",
        "    ax[i,0].set_ylabel(ritmo[i],fontsize=20)\n",
        "for j in range(ventanas_):\n",
        "     ax[0,j].set_title(f'{vwt[j,0]}--{vwt[j,1]} [s]',fontsize=15)\n",
        "\n",
        "plt.subplots_adjust(hspace=0.1,wspace=0.1)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:31:27.691073Z",
          "iopub.execute_input": "2025-12-12T23:31:27.691539Z",
          "iopub.status.idle": "2025-12-12T23:31:29.015444Z",
          "shell.execute_reply.started": "2025-12-12T23:31:27.691502Z",
          "shell.execute_reply": "2025-12-12T23:31:29.01434Z"
        },
        "id": "IN6V6qMuZq1C"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# calculamos las matrices de coectividades (correlación)\n",
        "\n",
        "N = X.shape[0]\n",
        "connectivities_v = np.array([np.corrcoef(X[i]) for i in range(N)])\n",
        "\n",
        "print(connectivities_v.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:31:29.016945Z",
          "iopub.execute_input": "2025-12-12T23:31:29.017289Z",
          "iopub.status.idle": "2025-12-12T23:31:29.195976Z",
          "shell.execute_reply.started": "2025-12-12T23:31:29.017253Z",
          "shell.execute_reply": "2025-12-12T23:31:29.194832Z"
        },
        "id": "URyaMN-rZq1D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from gcpds.visualizations.connectivities import CircosConnectivity\n",
        "\n",
        "N = len(channels)  # channels\n",
        "\n",
        "areas = {\n",
        "    'Frontal': ['Fpz', 'AFz', 'Fz', 'FCz'],\n",
        "    'Frontal Right': ['Fp2','AF4','AF8','F2','F4','F6','F8',],\n",
        "    'Central Right': ['FC2','FC4','FC6','FT8','C2','C4','C6','T8','CP2','CP4','CP6','TP8',],\n",
        "    'Posterior Right': ['P2','P4','P6','P8','P10','PO4','PO8','O2',],\n",
        "    'Central': ['Cz'],\n",
        "    'Posterior': ['CPz','Pz', 'Cz','POz','Oz','Iz',],\n",
        "    'Posterior Left': ['P1','P3','P5','P7','P9','PO3','PO7','O1',],\n",
        "    'Central Left': ['FC1','FC3','FC5','FT7','C1','C3','C5','T7','CP1','CP3','CP5','TP7',],\n",
        "    'Frontal Left': ['Fp1','AF3','AF7','F1','F3','F5','F7',],\n",
        "}\n",
        "\n",
        "\n",
        "conn = CircosConnectivity(\n",
        "    connectivities_v[0,:,:], channels, areas=areas, threshold=0.7,\n",
        "\n",
        "    # cmaps and themes\n",
        "    areas_cmap='Set3',\n",
        "    arcs_cmap='Wistia',\n",
        "    hemisphere_color='lightgray',\n",
        "    channel_color='#f8f9fa',\n",
        "    min_alpha=0,\n",
        "\n",
        "\n",
        "    # Texts\n",
        "    width={'hemispheres':35, 'areas':100, 'channels':60},\n",
        "    text={'hemispheres':40, 'areas':20,  'channels':40},\n",
        "    separation={'hemispheres':10, 'areas':-30, 'channels':5},\n",
        "    labelposition={'hemispheres':60, 'areas':0, 'channels':-10},\n",
        "    size=10,\n",
        "    labelsize=15,\n",
        "\n",
        "\n",
        "    # Shapes\n",
        "    show_emisphere=True,\n",
        "    arcs_separation=30,\n",
        "    connection_width=0.1,\n",
        "    small_separation=5,\n",
        "    big_separation=10,\n",
        "    offset=0,\n",
        ")\n",
        "\n",
        "conn.figure;\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:31:29.197088Z",
          "iopub.execute_input": "2025-12-12T23:31:29.19751Z",
          "iopub.status.idle": "2025-12-12T23:31:31.897332Z",
          "shell.execute_reply.started": "2025-12-12T23:31:29.197471Z",
          "shell.execute_reply": "2025-12-12T23:31:31.896076Z"
        },
        "id": "NQ6G8FOKZq1D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Topoplots"
      ],
      "metadata": {
        "id": "TJvu-A9mZq1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# promediemos por canales\n",
        "\n",
        "connecitivities_mean = np.mean(connectivities_v[0],axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:31:31.898365Z",
          "iopub.execute_input": "2025-12-12T23:31:31.898639Z",
          "iopub.status.idle": "2025-12-12T23:31:31.903133Z",
          "shell.execute_reply.started": "2025-12-12T23:31:31.898615Z",
          "shell.execute_reply": "2025-12-12T23:31:31.901966Z"
        },
        "id": "pqAEoUl-Zq1D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Solucion proyecto final\n",
        "\n",
        "## 1.2\n",
        "\n",
        "Presente una infografía que ilustre en qué consisten las señales de electroencefalografía (EEG) y su potencial aplicación en\n",
        "sistemas de interaccin cerebro computador (Brain Computer Interfaces- BCI) relacionados con el paradigma de imaginaci´ on\n",
        "motora (Motor Imagery- MI).\n",
        "\n",
        "https://github.com/1004516/PROYECTO_FINAL/blob/main/Infografia.pdf"
      ],
      "metadata": {
        "id": "z3fU64-uZq1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 2.2\n",
        "Con base en el estudio de la transformada Z y el diseño de filtros digitales presentado en el cuaderno Transformada Z, explique en qué consisten los filtros FIR e IIR, y como se utilizan para resaltar patrones espaciales, temporales y espectrales desde señales EEG en tareas de MI."
      ],
      "metadata": {
        "id": "es1RsFC4Zq1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el cuaderno de **Transformada Z y filtros digitales** se mostró que un SLIT discreto puede modelarse, al igual que en tiempo continuo con ecuaciones diferenciales, mediante **ecuaciones en diferencias** de la forma:\n",
        "\n",
        "$$ \\sum_{k=0}^{N} a_k y[n-k] = \\sum_{k=0}^{M} b_k x[n-k] $$\n",
        "\n",
        "Al aplicar la **transformada Z** y usar que $Z\\{x[n-k]\\} = z^{-k}X(z)$, dicha ecuación se convierte en una relación algebraica entre $Y(z)$ y $X(z)$:\n",
        "\n",
        "$$ \\left( \\sum_{k=0}^{N} a_k z^{-k} \\right) Y(z) = \\left( \\sum_{k=0}^{M} b_k z^{-k} \\right) X(z) $$\n",
        "\n",
        "De aquí se obtiene la **función de transferencia** del sistema:\n",
        "\n",
        "$$ H(z) = \\frac{Y(z)}{X(z)} = \\frac{\\sum_{k=0}^{M} b_k z^{-k}}{\\sum_{k=0}^{N} a_k z^{-k}} $$\n",
        "\n",
        "Esta expresión, escrita como cociente de polinomios en $z^{-1}$, permite clasificar los filtros digitales en dos ramas principales según los coeficientes del denominador: **filtros FIR** (cuando solo aparece $a_0$) y **filtros IIR** (cuando intervienen también $a_1, a_2, \\dots, a_N$).\n",
        "\n",
        "* En qué consisten los filtros FIR e IIR?"
      ],
      "metadata": {
        "id": "2XceWMvpZq1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tenemos la función de transferencia\n",
        "\n",
        "$$ H(z) = \\frac{\\sum_{k=0}^{M} b_k z^{-k}}{\\sum_{k=0}^{N} a_k z^{-k}}, $$\n",
        "\n",
        "los filtros se entienden así:\n",
        "\n",
        "### Filtros FIR (Finite Impulse Response)\n",
        "\n",
        "Un filtro FIR es aquel en el que el denominador solo tiene el término $a_0$ (que normalmente se toma como 1) y los demás coeficientes $a_k = 0$ para $k \\ge 1$. Entonces,\n",
        "\n",
        "$$ H(z) = \\frac{\\sum_{k=0}^{M} b_k z^{-k}}{1} $$\n",
        "\n",
        "y en el tiempo la ecuación queda:\n",
        "\n",
        "$$ y[n] = \\sum_{k=0}^{M} b_k x[n-k]. $$\n",
        "\n",
        "En otras palabras, el filtro calcula la salida usando únicamente la muestra actual de la señal y un número limitado de muestras anteriores, sin reutilizar salidas anteriores del propio filtro. Por eso, cuando le entra un impulso, su efecto solo dura unas pocas muestras y luego desaparece, y se dice que el filtro tiene una respuesta al impulso finita.\n",
        "\n",
        "### Filtros IIR (Infinite Impulse Response)\n",
        "\n",
        "En un filtro IIR el denominador tiene, además de $a_0$, otros coeficientes $a_1, a_2, \\dots, a_N$ distintos de cero:\n",
        "\n",
        "$$ H(z) = \\frac{\\sum_{k=0}^{M} b_k z^{-k}}{\\sum_{k=0}^{N} a_k z^{-k}}. $$\n",
        "\n",
        "Al llevar esto al dominio del tiempo, la ecuación queda:\n",
        "\n",
        "$$ a_0y[n] + a_1y[n-1] + \\dots + a_Ny[n-N] = \\sum_{k=0}^{M} b_k x[n-k], $$\n",
        "\n",
        "y al despejar $y[n]$ se observa que, para calcular la salida en el instante\n",
        "𝑛, el filtro utiliza tanto valores anteriores de la señal de entrada como valores anteriores de la propia salida. Como el sistema se alimenta de estos valores previos de salida, el efecto de un solo impulso puede prolongarse durante mucho tiempo (en teoría, no desaparecer por completo), y por eso a estos filtros se les conoce como de respuesta al impulso infinita (IIR)."
      ],
      "metadata": {
        "id": "RpX9ukiSZq1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " * como se utilizan para resaltar patrones **espaciales** desde señales EEG en tareas de MI.\n",
        "\n",
        " En el contexto de tareas de imaginación motora (MI), los filtros digitales FIR e IIR se utilizan sobre las señales EEG para resaltar los patrones espaciales asociados a diferentes movimientos imaginados. En primer lugar, se aplica a cada canal de EEG (por ejemplo, C3, Cz, C4, etc.) un filtro FIR o IIR diseñado como pasa–banda en las frecuencias de interés, típicamente en las bandas μ (8–13 Hz) y β (13–30 Hz), junto con filtros adicionales para atenuar el ruido y la interferencia de la red eléctrica. De esta manera, en cada electrodo se conserva principalmente la actividad relacionada con los ritmos motores y se reducen componentes no relevantes.\n",
        "\n",
        "En segundo lugar, a partir de las señales ya filtradas, se calcula para cada canal una medida de potencia o energía en dichas bandas de frecuencia. Finalmente, estos valores se comparan entre diferentes posiciones del casco de electrodos, lo que permite identificar qué regiones muestran mayores cambios durante la MI (por ejemplo, variaciones más marcadas en C3 para la mano derecha y en C4 para la mano izquierda). Este procedimiento hace que los filtros FIR e IIR sean una etapa fundamental para limpiar la señal y realzar las diferencias entre electrodos, facilitando así la visualización y análisis de los patrones espaciales asociados a la actividad motora imaginada.\n",
        "\n",
        "\n",
        "* como se utilizan para resaltar patrones **temporales** desde señales EEG en tareas de MI.\n",
        "\n",
        "En tareas de imaginación motora (MI), los filtros digitales FIR e IIR se emplean para resaltar patrones temporales en las señales EEG, es decir, los cambios que se producen antes, durante y después del periodo en el que el sujeto imagina el movimiento. En una primera etapa, se aplican filtros pasa–altos, pasa–bajos, pasa–banda y, cuando es necesario, filtros “notch” (por ejemplo, para atenuar la interferencia de 50/60 Hz). Estos filtros, implementados como FIR o IIR, permiten eliminar tendencias lentas (deriva), ruido de alta frecuencia y componentes periódicas no relacionadas con la tarea, dejando una señal más limpia en el dominio del tiempo.\n",
        "\n",
        "Una vez filtrado el EEG, se segmentan las señales alrededor de los eventos de interés (por ejemplo, la aparición de una pista visual o el inicio de la imaginación del movimiento) y se analizan las variaciones de amplitud y forma de onda a lo largo del tiempo. De esta manera, es posible observar con mayor claridad cómo evoluciona la actividad cerebral durante la preparación, ejecución imaginada y relajación del movimiento, identificando fenómenos como descensos o incrementos de actividad en intervalos temporales específicos (ERD/ERS). En conjunto, el uso de filtros FIR e IIR constituye una etapa clave para suprimir artefactos y realzar la estructura temporal de la señal, facilitando la interpretación de los cambios dinámicos asociados a la imaginación motora.\n",
        "\n",
        "\n",
        "* como se utilizan para resaltar patrones **espectrales** desde señales EEG en tareas de MI.\n",
        "\n",
        "En tareas de imaginación motora (MI), los filtros digitales FIR e IIR se utilizan para resaltar patrones espectrales en las señales EEG, es decir, los cambios en la distribución de energía de la señal a lo largo de las distintas frecuencias. En particular, se busca aislar las bandas relacionadas con la actividad motora, como los ritmos μ (aprox. 8–13 Hz) y β (aprox. 13–30 Hz). Para ello, se diseñan filtros pasa–banda FIR o IIR centrados en estas bandas de frecuencia y se aplican de forma independiente a cada canal de EEG. De esta manera, se atenúan las componentes que no pertenecen a dichas bandas y se enfatiza la actividad espectral asociada a la MI.\n",
        "\n",
        "Una vez filtrada la señal en las bandas de interés, se calcula la potencia espectral o la energía de cada canal en ventanas de tiempo definidas (por ejemplo, antes, durante y después del periodo de imaginación del movimiento). Esto permite observar con mayor claridad fenómenos como disminuciones de potencia (ERD) o aumentos de potencia (ERS) en las bandas μ y β, que están directamente relacionados con la preparación y ejecución imaginada del movimiento. En conjunto, el uso de filtros FIR e IIR como filtros pasa–banda constituye una herramienta fundamental para aislar las frecuencias relevantes y realzar los patrones espectrales característicos de la imaginación motora en EEG."
      ],
      "metadata": {
        "id": "oMx2KJNgZq1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Punto 2.3\n",
        "Adaptar y modificar el código base del cuaderno del punto 2.1 para mejorar la detección de patrones de imaginación motora en distintos sujetos y condiciones experimentales. Discuta las dificultades encontradas respecto a lo estudiado en el estado del arte, especialmente, respecto a la inconsistencia en la identificación de patrones espaciales, temporales y frecuenciales en estas señales entre sujetos y estímulos.\n",
        "<!--  -->\n",
        "# SOLUCION\n",
        "\n",
        "En este trabajo se adaptó y modificó el código base del cuaderno del punto 2.1 con el objetivo de mejorar la detección de patrones de imaginación motora en distintos sujetos y condiciones experimentales. Para ello, se implementó la carga por lotes de varios participantes, se aplicó una normalización por sujeto sobre los ensayos de EEG y se utilizó una representación tiempo–frecuencia basada en un banco de filtros y ventanas de tiempo. Sobre esta representación se entrenó un esquema de FBCSP (Filter-Bank CSP) combinado con validación cruzada agrupada por sujeto, de forma que los patrones extraídos se evalúan dejando sujetos completos fuera del entrenamiento."
      ],
      "metadata": {
        "id": "5UpdUT73Zq1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de varios sujetos y evaluación de CSP con banco de filtros (filter-bank)\n",
        "from mne.decoding import CSP\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GroupKFold, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Sacamos la lista de sujetos desde la base de datos.\n",
        "# Si no existe ese atributo, usamos por defecto los sujetos del 1 al 5.\n",
        "sbj_list = getattr(db, \"subjects\", None)\n",
        "if sbj_list is None:\n",
        "    sbj_list = list(range(1, 6))\n",
        "print(f\"Using {len(sbj_list)} subjects: {sbj_list}\")\n",
        "\n",
        "# Definimos las bandas de frecuencia donde suele aparecer la imaginación motora\n",
        "# Cada fila de f_bank es [frecuencia_inicial, frecuencia_final] en Hz\n",
        "f_bank = np.array([[4.0, 8.0], [8.0, 13.0], [13.0, 26.0], [26.0, 35.0]])\n",
        "\n",
        "# Ventanas de tiempo (en segundos) donde vamos a mirar la señal respecto al estímulo\n",
        "# Cada fila es [tiempo_inicial, tiempo_final]\n",
        "vwt = np.array([[0.5, 2.5], [2.0, 4.0], [3.5, 5.5]])  # ventanas de 2.0 s\n",
        "\n",
        "# Objeto que se encarga de aplicar el banco de filtros y las ventanas de tiempo\n",
        "tf_repr = TimeFrequencyRpr(sfreq=new_fs, f_bank=f_bank, vwt=vwt)\n",
        "\n",
        "\n",
        "def center_scale_trials(X: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Subject-wise centering and scaling to reduce between-subject amplitude drift.\"\"\"\n",
        "    # Restamos la media en el tiempo para que cada canal quede centrado en 0\n",
        "    X = X - X.mean(axis=2, keepdims=True)\n",
        "    # Dividimos por la desviación estándar para que la escala de amplitud sea parecida\n",
        "    # entre ensayos (evitamos división por 0 sumando un valor muy pequeño)\n",
        "    X = X / (X.std(axis=2, keepdims=True) + 1e-6)\n",
        "    return X\n",
        "\n",
        "\n",
        "def load_subject_tf(sbj: int):\n",
        "    # Cargamos los datos crudos del sujeto con la función load_GIGA\n",
        "    X, y = load_GIGA(sbj=sbj, **load_args)\n",
        "    # Normalizamos los ensayos de este sujeto\n",
        "    X = center_scale_trials(X)\n",
        "    # Aplicamos la representación tiempo-frecuencia y quitamos ejes extra\n",
        "    return np.squeeze(tf_repr.transform(X)), y\n",
        "\n",
        "\n",
        "# Aquí vamos a juntar los datos de todos los sujetos\n",
        "# X_all: señales, y_all: etiquetas, groups: a qué sujeto pertenece cada ensayo\n",
        "X_all, y_all, groups = [], [], []\n",
        "for sbj in sbj_list:\n",
        "    # Obtenemos los datos tiempo-frecuencia de este sujeto\n",
        "    X_tf, y = load_subject_tf(sbj)\n",
        "    # Guardamos los datos y las etiquetas en listas\n",
        "    X_all.append(X_tf)\n",
        "    y_all.append(y)\n",
        "    # En groups repetimos el número de sujeto tantas veces como ensayos tenga\n",
        "    groups.extend([sbj] * len(y))\n",
        "\n",
        "# Unimos todos los sujetos en un solo arreglo grande\n",
        "X_all = np.concatenate(X_all, axis=0)\n",
        "y_all = np.concatenate(y_all, axis=0)\n",
        "groups = np.asarray(groups)\n",
        "print(\"Time-frequency tensor:\", X_all.shape, \"labels:\", y_all.shape)\n",
        "\n",
        "\n",
        "class FBCSPFeatures(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Filter-bank CSP over bands and windows with log-variance features.\"\"\"\n",
        "\n",
        "    def __init__(self, n_components: int = 2):\n",
        "        # Cantidad de componentes CSP que vamos a sacar por cada banda y ventana\n",
        "        self.n_components = n_components\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # X tiene forma (ensayos, canales, tiempo, ventanas, bandas)\n",
        "        # Aquí entrenamos un CSP para cada combinación banda–ventana\n",
        "        self.csp_bank_ = []\n",
        "        n_bands = X.shape[-1]     # cuántas bandas de frecuencia hay\n",
        "        n_windows = X.shape[-2]   # cuántas ventanas de tiempo hay\n",
        "\n",
        "        for b in range(n_bands):\n",
        "            for w in range(n_windows):\n",
        "                # Creamos un CSP para esta banda y esta ventana\n",
        "                csp = CSP(\n",
        "                    n_components=self.n_components,\n",
        "                    log=True,\n",
        "                    transform_into=\"average_power\",\n",
        "                )\n",
        "                # Entrenamos el CSP usando solo esa banda y ventana\n",
        "                csp.fit(X[:, :, :, w, b], y)\n",
        "                # Guardamos la pareja (banda, ventana, modelo CSP)\n",
        "                self.csp_bank_.append((b, w, csp))\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Aplicamos todos los CSP entrenados para sacar las características\n",
        "        feats = []\n",
        "        for b, w, csp in self.csp_bank_:\n",
        "            # Extraemos las características CSP de esa banda y ventana\n",
        "            feats.append(csp.transform(X[:, :, :, w, b]))\n",
        "        # Unimos todas las características en una sola matriz\n",
        "        return np.concatenate(feats, axis=1)\n",
        "\n",
        "\n",
        "# Definimos en cuántas partes queremos dividir los datos para validación cruzada\n",
        "# Usamos entre 2 y 5 particiones, dependiendo de cuántos sujetos haya\n",
        "n_splits = max(2, min(5, len(np.unique(groups))))\n",
        "\n",
        "# GroupKFold se asegura de que los datos de un mismo sujeto estén juntos,\n",
        "# es decir, un sujeto no se parte entre entrenamiento y prueba\n",
        "gkf = GroupKFold(n_splits=n_splits)\n",
        "\n",
        "# Creamos un pipeline que:\n",
        "# 1) Saca características con FBCSP\n",
        "# 2) Estandariza las características\n",
        "# 3) Aplica una regresión logística para clasificar\n",
        "clf = Pipeline(\n",
        "    steps=[\n",
        "        (\"fbcsp\", FBCSPFeatures(n_components=2)),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\n",
        "            \"logreg\",\n",
        "            LogisticRegression(\n",
        "                max_iter=1000,\n",
        "                class_weight=\"balanced\",  # ayuda cuando hay más ejemplos de una clase que de otra\n",
        "                solver=\"lbfgs\",\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Evaluamos el modelo usando validación cruzada por sujeto.\n",
        "# scoring=\"roc_auc\" mide qué tan bien separa las clases (área bajo la curva ROC).\n",
        "scores = cross_val_score(\n",
        "    clf, X_all, y_all, groups=groups, cv=gkf, scoring=\"roc_auc\"\n",
        ")\n",
        "print(\"Group-wise (subject-held-out) AUC:\", scores, \"mean=\", scores.mean())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-12T23:31:31.904337Z",
          "iopub.execute_input": "2025-12-12T23:31:31.904635Z",
          "iopub.status.idle": "2025-12-12T23:35:38.270979Z",
          "shell.execute_reply.started": "2025-12-12T23:31:31.904611Z",
          "shell.execute_reply": "2025-12-12T23:35:38.269764Z"
        },
        "id": "Y6BG9tDHZq1G"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dificultades vs estado del arte\n",
        "\n",
        "A partir de estas modificaciones se observaron varias dificultades que coinciden con lo reportado en el estado del arte, especialmente respecto a la inconsistencia de los patrones espaciales, temporales y frecuenciales entre sujetos y estímulos:\n",
        "\n",
        "**Inconsistencia espacial:**\n",
        "Las fuentes sensorimotores no aparecen exactamente en los mismos electrodos para todos los sujetos (diferencias en anatomía, colocación del casco, etc.). Por eso, los filtros CSP ajustados en un sujeto no se transfieren bien a otro sin algún tipo de alineamiento. En la literatura se mencionan enfoques como alineamiento Riemanniano o estimación de fuentes para hacer más estable la estructura de covarianzas entre sujetos.\n",
        "\n",
        "**Variabilidad espectral:**\n",
        "Las bandas μ y β no son fijas; sus picos pueden desplazarse por fatiga, medicamentos o cambios en la impedancia de los electrodos. Aunque aquí se usan bandas fijas con un banco de filtros, esto puede no capturar bien los picos específicos de cada persona. En el estado del arte se proponen enfoques más adaptativos, como selección de picos por sujeto o modelos espectrales personalizados.\n",
        "\n",
        "**Desfase temporal (temporal jitter):**\n",
        "El inicio de la imaginación motora y la dinámica ERD/ERS no ocurre exactamente al mismo tiempo en todos los ensayos. Al trabajar con ventanas temporales fijas, se corre el riesgo de dejar por fuera parte de la información relevante. Por eso, en trabajos recientes se usan ventanas deslizantes más flexibles o métodos que ajustan la latencia de forma automática, aunque suelen requerir más datos y modelos más complejos.\n",
        "\n",
        "**Ruido no estacionario:**\n",
        "Artefactos musculares, oculares y ruido de línea cambian entre sesiones y sujetos, afectando tanto la covarianza como el espectro de la señal. En este código solo se aborda parcialmente el problema con una normalización por ensayo/sujeto, mientras que en el estado del arte se utilizan técnicas más avanzadas como ICA, SSP o estimadores de covarianza más robustos.\n",
        "\n",
        "**Generalización entre condiciones:**\n",
        "La imaginación motora (por ejemplo, izquierda/derecha) puede verse mezclada con movimientos reales, diferencias en las instrucciones o cambios en las condiciones del experimento. En la literatura se proponen métodos de adaptación de dominio y meta–aprendizaje para manejar estos cambios. En nuestro caso, el uso de FBCSP con banco de filtros, varias ventanas de tiempo y validación cruzada agrupada por sujeto ayuda a reducir parte de la variabilidad, pero las inconsistencias espaciales, temporales y espectrales siguen siendo un cuello de botella importante, tal como se discute en los trabajos actuales sobre MI–BCI.\n"
      ],
      "metadata": {
        "id": "cuEbKRBrZq1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.4\n",
        "\n",
        "Presente un nuevo cuaderno con la solución propuesta, indicando la influencia de artefactos fisiológicos (ej., parpadeo, actividad muscular) y factores genéticos, cognitivos y de experiencia previa, relacionados con la variabilidad de las señales entre sujetos."
      ],
      "metadata": {
        "id": "n1sR3JDGZq1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí se retoma la solución implementada en el punto 2.3 (banco de filtros, ventanas de tiempo, FBCSP y validación cruzada agrupada por sujeto) y se analiza cómo distintos factores del sujeto y de la señal influyen en la variabilidad entre participantes y, en consecuencia, en el rendimiento del modelo, teniendo en cuenta que las señales de EEG pueden cambiar bastante de una persona a otra por varios motivos.\n",
        "\n",
        "Primero, **los artefactos fisiológicos** afectan mucho la señal. Por ejemplo, los parpadeos y los movimientos de los ojos generan picos grandes en los electrodos frontales, y la actividad muscular en cara y cuello mete energía en frecuencias altas (más de 30–40 Hz). Si no se controlan, estos artefactos pueden “engañar” a CSP y hacer que aprenda más ruido que imaginación motora. Por eso en la solución se considera el uso de filtrado (notch, pasaaltos) y la revisión de ensayos muy ruidosos que podrían ser descartados.\n",
        "\n",
        "También influyen **factores fisiológicos y genéticos**. Cada sujeto tiene diferencias en su cerebro y en cómo se organizan las áreas motoras, así que las bandas μ y β no aparecen exactamente igual para todos. Esto ayuda a explicar por qué, aunque usemos el mismo banco de filtros, algunos sujetos muestran patrones más claros que otros.\n",
        "\n",
        "A esto se suman **factores cognitivos**, como la fatiga o el nivel de atención. Cuando una persona está cansada o distraída, la potencia de las bandas μ/β y la profundidad del ERD cambian, y eso se nota en el desempeño del modelo. La normalización por sujeto y el uso de varias ventanas temporales ayudan un poco a compensar estos cambios de estado.\n",
        "\n",
        "Por último, **la experiencia previa y la estrategia de imaginación** también juegan un papel. No todos imaginan el movimiento de la misma forma (algunos se enfocan más en “sentir” el movimiento y otros en visualizarlo), y no todos tienen la misma práctica. Esto hace que la activación aparezca en lugares y tiempos diferentes. Con las múltiples ventanas de tiempo y la validación dejando sujetos por fuera se puede ver que el modelo tiene que lidiar con toda esta variabilidad, y que por eso no siempre generaliza perfecto entre personas.\n",
        "\n",
        "## 2.5\n",
        "\n",
        "Presente una infografía que resuma los conceptos y desarrollos implementados respecto al reconocimiento de señales de EEG en\n",
        "tareas de MI.\n",
        "\n",
        "https://github.com/david-1192/Senales_y_Sistemas_2025/blob/main/EEG%20se%C3%B1ales%20info.pdf"
      ],
      "metadata": {
        "id": "H3QHP0U0Zq1H"
      }
    }
  ]
}